{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "45e9398d-eea0-4ca6-8db5-d64a7f38078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Configuration\n",
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import pdf2image\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "if sys.platform == \"win32\":\n",
    "    poppler_path = r\"C:\\Program Files\\poppler\\Library\\bin\"  # <-- UPDATE THIS PATH\n",
    "    if os.path.exists(poppler_path):\n",
    "        os.environ[\"PATH\"] += os.pathsep + poppler_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2c86022a-d149-4cc0-8eab-c62ddffeb2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Data Classes\n",
    "@dataclass\n",
    "class Addback:\n",
    "    \"\"\"Represents a single addback item\"\"\"\n",
    "    line_item: str\n",
    "    amount: float\n",
    "    reason: str\n",
    "    calculation: str = \"\"\n",
    "    source: str = \"Tax Return\"\n",
    "    confidence: float = 1.0  # 0-1 confidence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3054bd6d-4b54-4d24-99e0-9477dd05a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Complete ProductionAddbackAnalyzer Class\n",
    "class ProductionAddbackAnalyzer:\n",
    "    \"\"\"Production-ready analyzer that works automatically without manual intervention\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.market_rate_salary = 195700\n",
    "        \n",
    "        # Enhanced patterns with multiple variations for better OCR matching\n",
    "        self.extraction_patterns = {\n",
    "            \"depreciation\": {\n",
    "                \"primary_patterns\": [\n",
    "                    # EXACT text from the form\n",
    "                    r\"MACRS deductions for assets placed in service.*?(\\d{1,3}[,.]?\\d{3})\",\n",
    "                    r\"MACRS.*beginning before.*?(\\d{1,3}[,.]?\\d{3})\",\n",
    "                    # Also try just the number pattern near MACRS\n",
    "                    r\"MACRS.*?(\\d{1,3}[,.]?\\d{3})\",\n",
    "                    # Line 17 reference\n",
    "                    r\"(?:line\\s*)?17[^\\d]*?(\\d{1,3}[,.]?\\d{3})\"\n",
    "                ],\n",
    "                \"context_patterns\": [\n",
    "                    # Look for 1,373 specifically\n",
    "                    r\"1[,.]?373\",\n",
    "                    # Depreciation but NOT total\n",
    "                    r\"(?<!total).*depreciation.*?(\\d{1,3}[,.]?\\d{3})\"\n",
    "                ],\n",
    "                \"exclusion_patterns\": [\n",
    "                    r\"total.*depreciation\",\n",
    "                    r\"line\\s*21\",\n",
    "                    r\"line\\s*22\"\n",
    "                ],\n",
    "                \"form_line\": \"Form 4562 Line 17 (MACRS)\"\n",
    "            },\n",
    "            \"officer_compensation\": {\n",
    "                \"primary_patterns\": [\n",
    "                    r\"HARVEY.*SEYBOLD.*?[\\$\\s]*(\\d{3}[,.]?\\d{3})\",\n",
    "                    r\"compensation.*officers.*?[\\$\\s]*(\\d{3}[,.]?\\d{3})\",\n",
    "                    r\"Form\\s+1125-E.*line\\s+[24].*?[\\$\\s]*(\\d{3}[,.]?\\d{3})\"\n",
    "                ],\n",
    "                \"context_patterns\": [\n",
    "                    r\"200[,.]?115\"  # Look for the specific amount\n",
    "                ],\n",
    "                \"form_line\": \"Form 1125-E Line 2\"\n",
    "            },\n",
    "            # In your __init__ method, update the automobile patterns:\n",
    "            \"automobile\": {\n",
    "                \"primary_patterns\": [\n",
    "                    # More flexible patterns\n",
    "                    r\"automobile\\s+and\\s+truck\\s+expense[s]?[:\\s]*\\$?\\s*([0-9]{1,2}[,.]?[0-9]{3})\",\n",
    "                    r\"automobile[^0-9]{0,30}([0-9]{1,2}[,.]?[0-9]{3})\",\n",
    "                    r\"auto.*?truck.*?([0-9]{1,2}[,.]?[0-9]{3})\",\n",
    "                    # Look for the amount even if OCR mangles the text\n",
    "                    r\"(?:auto|truck|vehicle).*?expenses?.*?([0-9]{1,2}[,.]?[0-9]{3})\",\n",
    "                ],\n",
    "                \"context_patterns\": [\n",
    "                    # Just find 5-digit numbers near automobile text\n",
    "                    r\"([0-9]{1,2}[,.]?[0-9]{3})(?=[^0-9]|$)\",\n",
    "                ],\n",
    "                \"form_line\": \"Other Deductions - Schedule K\"\n",
    "            },\n",
    "            \"meals\": {\n",
    "                \"primary_patterns\": [\n",
    "                    r\"meals.*\\(?50%\\)?.*?[\\$\\s]*(\\d{1,3})\",\n",
    "                    r\"MEALS.*?[\\$\\s]*(\\d{1,3})\",\n",
    "                    r\"meals.*entertainment.*?[\\$\\s]*(\\d{1,3}[,.]?\\d{3})\"\n",
    "                ],\n",
    "                \"context_patterns\": [\n",
    "                    r\"meal[^\\d]*(\\d{1,3})\"\n",
    "                ],\n",
    "                \"form_line\": \"Other Deductions\"\n",
    "            },\n",
    "            \"charitable\": {\n",
    "                \"primary_patterns\": [\n",
    "                    r\"charitable.*contrib.*?[\\$\\s]*(\\d{1,3}[,.]?\\d{3})\",\n",
    "                    r\"CHARITABLE.*?[\\$\\s]*(\\d{1,3}[,.]?\\d{3})\"\n",
    "                ],\n",
    "                \"context_patterns\": [\n",
    "                    r\"contribution[^\\d]*(\\d{1,3}[,.]?\\d{3})\"\n",
    "                ],\n",
    "                \"form_line\": \"M-2 Line 5\"\n",
    "            },\n",
    "            \"section179\": {\n",
    "                \"primary_patterns\": [\n",
    "                    r\"section\\s+179\\s+expense.*?[\\$\\s]*(\\d{2,3}[,.]?\\d{3})\",\n",
    "                    r\"SEC.*179.*?[\\$\\s]*(\\d{2,3}[,.]?\\d{3})\"\n",
    "                ],\n",
    "                \"context_patterns\": [\n",
    "                    r\"179[^\\d]*(\\d{2,3}[,.]?\\d{3})\"\n",
    "                ],\n",
    "                \"form_line\": \"M-2 Line 5\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.addback_rules = {\n",
    "            \"officer_compensation\": {\n",
    "                \"calc_type\": \"excess_over_market\",\n",
    "                \"reason\": \"Owner salary exceeds market rate. Excess amount is added back to normalize earnings.\"\n",
    "            },\n",
    "            \"depreciation\": {\n",
    "                \"calc_type\": \"full_amount\",\n",
    "                \"reason\": \"Non-cash expense. Added back for EBITDA calculation as it doesn't affect cash flow.\"\n",
    "            },\n",
    "            \"automobile\": {\n",
    "                \"calc_type\": \"percentage\",\n",
    "                \"percentage\": 0.25,\n",
    "                \"reason\": \"25% assumed personal use. This portion is discretionary/non-business expense.\"\n",
    "            },\n",
    "            \"meals\": {\n",
    "                \"calc_type\": \"full_amount\",\n",
    "                \"reason\": \"Non-deductible portion (50%) represents discretionary spending.\"\n",
    "            },\n",
    "            \"charitable\": {\n",
    "                \"calc_type\": \"full_amount\",\n",
    "                \"reason\": \"Non-business expense. Charitable giving is discretionary.\"\n",
    "            },\n",
    "            \"section179\": {\n",
    "                \"calc_type\": \"full_amount\",\n",
    "                \"reason\": \"Accelerated depreciation election. Added back as it's a non-cash tax benefit.\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def preprocess_image_advanced(self, image):\n",
    "        \"\"\"Advanced image preprocessing for better OCR - especially numbers\"\"\"\n",
    "        # Convert to numpy array for advanced processing\n",
    "        img_array = np.array(image)\n",
    "        \n",
    "        # Convert to grayscale if not already\n",
    "        if len(img_array.shape) == 3:\n",
    "            gray = np.dot(img_array[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "        else:\n",
    "            gray = img_array\n",
    "        \n",
    "        # Import cv2 for better preprocessing\n",
    "        try:\n",
    "            import cv2\n",
    "            \n",
    "            # Convert to uint8\n",
    "            gray_uint8 = gray.astype(np.uint8)\n",
    "            \n",
    "            # 1. Denoise while preserving edges (good for numbers)\n",
    "            denoised = cv2.bilateralFilter(gray_uint8, 9, 75, 75)\n",
    "            \n",
    "            # 2. Apply adaptive thresholding (better for varying lighting)\n",
    "            thresh = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                         cv2.THRESH_BINARY, 11, 2)\n",
    "            \n",
    "            # 3. Morphological operations to connect broken digits\n",
    "            kernel = np.ones((2,1), np.uint8)  # Vertical kernel to connect digit parts\n",
    "            connected = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "            \n",
    "            # 4. Remove small noise\n",
    "            kernel_noise = np.ones((2,2), np.uint8)\n",
    "            cleaned = cv2.morphologyEx(connected, cv2.MORPH_OPEN, kernel_noise)\n",
    "            \n",
    "            # Convert back to PIL\n",
    "            pil_img = Image.fromarray(cleaned)\n",
    "            \n",
    "        except ImportError:\n",
    "            # Fallback if cv2 not available\n",
    "            print(\"Warning: cv2 not available. Using basic preprocessing.\")\n",
    "            pil_img = Image.fromarray(gray.astype(np.uint8))\n",
    "            \n",
    "            # Basic enhancement\n",
    "            enhancer = ImageEnhance.Contrast(pil_img)\n",
    "            pil_img = enhancer.enhance(2.5)\n",
    "            pil_img = pil_img.filter(ImageFilter.SHARPEN)\n",
    "            pil_img = pil_img.point(lambda x: 0 if x < 128 else 255, '1')\n",
    "        \n",
    "        return pil_img\n",
    "\n",
    "    def extract_at_multiple_resolutions(self, image, pattern_dict):\n",
    "        \"\"\"Try OCR at different resolutions - helps with number recognition\"\"\"\n",
    "        findings = []\n",
    "        \n",
    "        # Try different DPIs/scales\n",
    "        for scale in [1.0, 1.5, 2.0, 2.5]:\n",
    "            if scale != 1.0:\n",
    "                new_size = (int(image.width * scale), int(image.height * scale))\n",
    "                scaled_img = image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "            else:\n",
    "                scaled_img = image\n",
    "            \n",
    "            # Preprocess the scaled image\n",
    "            processed = self.preprocess_image_advanced(scaled_img)\n",
    "            \n",
    "            # Try OCR with different configs\n",
    "            for config in ['--psm 6', '--psm 4 -c tessedit_char_whitelist=0123456789,$,. ']:\n",
    "                try:\n",
    "                    text = pytesseract.image_to_string(processed, config=config)\n",
    "                    \n",
    "                    # Extract numbers near \"automobile\"\n",
    "                    if 'automobile' in text.lower():\n",
    "                        # Look for numbers within 50 characters of 'automobile'\n",
    "                        auto_match = re.search(r'automobile[^0-9]{0,50}(\\d{1,2}[,.]?\\d{3})', \n",
    "                                             text, re.IGNORECASE)\n",
    "                        if auto_match:\n",
    "                            value = auto_match.group(1).replace(',', '').replace('.', '')\n",
    "                            try:\n",
    "                                findings.append((float(value), 0.7))\n",
    "                            except:\n",
    "                                pass\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        return findings\n",
    "    \n",
    "    def extract_with_validation(self, pdf_path: str) -> Dict[str, List[Tuple[float, float]]]:\n",
    "        \"\"\"Extract values with confidence scores\"\"\"\n",
    "        try:\n",
    "            if sys.platform == \"win32\" and 'poppler_path' in globals():\n",
    "                images = pdf2image.convert_from_path(pdf_path, dpi=400, poppler_path=poppler_path)\n",
    "            else:\n",
    "                images = pdf2image.convert_from_path(pdf_path, dpi=400)\n",
    "            \n",
    "            all_findings = {key: [] for key in self.extraction_patterns.keys()}\n",
    "            \n",
    "            for page_num, image in enumerate(images):\n",
    "                print(f\"Processing page {page_num + 1}...\")\n",
    "                # Try multiple preprocessing approaches\n",
    "                preprocessing_methods = [\n",
    "                    (\"original\", image),\n",
    "                    (\"enhanced\", self.preprocess_image_advanced(image)),\n",
    "                    (\"high_contrast\", ImageEnhance.Contrast(image.convert('L')).enhance(3.0)),\n",
    "                    (\"sharpened\", image.filter(ImageFilter.SHARPEN).filter(ImageFilter.SHARPEN))\n",
    "                ]\n",
    "                # Add special handling for automobile if it's in our missing items\n",
    "                if page_num >= 3:  # Other Deductions usually on later pages\n",
    "                    # Try targeted extraction for automobile expense\n",
    "                    auto_findings = self.extract_at_multiple_resolutions(image, \n",
    "                                                                       self.extraction_patterns.get(\"automobile\", {}))\n",
    "                    if auto_findings:\n",
    "                        all_findings[\"automobile\"].extend(auto_findings)\n",
    "                \n",
    "                for method_name, processed_img in preprocessing_methods:\n",
    "                    # Use multiple OCR passes with different settings\n",
    "                    for psm in [6, 4, 11]:  # Different page segmentation modes\n",
    "                        try:\n",
    "                            text = pytesseract.image_to_string(\n",
    "                                processed_img, \n",
    "                                config=f'--psm {psm} --oem 3'\n",
    "                            )\n",
    "                            \n",
    "                            # Extract values for each category\n",
    "                            for category, patterns in self.extraction_patterns.items():\n",
    "                                # Check if this text contains exclusion patterns\n",
    "                                should_skip = False\n",
    "                                for exclusion in patterns.get(\"exclusion_patterns\", []):\n",
    "                                    if re.search(exclusion, text, re.IGNORECASE):\n",
    "                                        should_skip = True\n",
    "                                        break\n",
    "                                \n",
    "                                if should_skip and category == \"depreciation\":\n",
    "                                    continue  # Skip this text block for depreciation\n",
    "                                \n",
    "                                # Try primary patterns first (higher confidence)\n",
    "                                for pattern in patterns[\"primary_patterns\"]:\n",
    "                                    matches = re.finditer(pattern, text, re.IGNORECASE | re.MULTILINE)\n",
    "                                    for match in matches:\n",
    "                                        value_str = match.group(1).replace(',', '').replace('.', '')\n",
    "                                        try:\n",
    "                                            value = float(value_str)\n",
    "                                            # High confidence for primary patterns\n",
    "                                            all_findings[category].append((value, 0.9))\n",
    "                                        except:\n",
    "                                            continue\n",
    "                                \n",
    "                                # Try context patterns (lower confidence)\n",
    "                                for pattern in patterns.get(\"context_patterns\", []):\n",
    "                                    matches = re.finditer(pattern, text, re.IGNORECASE | re.MULTILINE)\n",
    "                                    for match in matches:\n",
    "                                        # Handle patterns that might just find the number itself\n",
    "                                        if match.groups():\n",
    "                                            value_str = match.group(1).replace(',', '').replace('.', '')\n",
    "                                        else:\n",
    "                                            value_str = match.group(0).replace(',', '').replace('.', '')\n",
    "                                        try:\n",
    "                                            value = float(value_str)\n",
    "                                            # Lower confidence for context patterns\n",
    "                                            all_findings[category].append((value, 0.6))\n",
    "                                        except:\n",
    "                                            continue\n",
    "                        except:\n",
    "                            continue\n",
    "            \n",
    "            return all_findings\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in extraction: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def select_best_value(self, findings: List[Tuple[float, float]], category: str = None) -> Optional[float]:\n",
    "        \"\"\"Select the most likely correct value from multiple findings\"\"\"\n",
    "        if not findings:\n",
    "            return None\n",
    "        \n",
    "        # Debug print for depreciation\n",
    "        if category == \"depreciation\":\n",
    "            print(f\"\\nDEBUG - All depreciation values found:\")\n",
    "            for value, confidence in sorted(findings):\n",
    "                print(f\"  ${value:,.0f} (confidence: {confidence})\")\n",
    "        \n",
    "        # Special handling for depreciation - prefer smaller values (likely MACRS not total)\n",
    "        if category == \"depreciation\":\n",
    "            # Filter out values that are likely totals (too large)\n",
    "            reasonable_findings = [(v, c) for v, c in findings if v < 3000]\n",
    "            if reasonable_findings:\n",
    "                print(f\"  After filtering < $3,000: {len(reasonable_findings)} values remain\")\n",
    "                findings = reasonable_findings\n",
    "            \n",
    "            # Prefer values around 1,000-2,000 for MACRS\n",
    "            macrs_range_findings = [(v, c) for v, c in findings if 1000 <= v <= 2000]\n",
    "            if macrs_range_findings:\n",
    "                print(f\"  Values in MACRS range ($1,000-$2,000): {len(macrs_range_findings)}\")\n",
    "                findings = macrs_range_findings\n",
    "        \n",
    "        # For automobile, debug what we're seeing\n",
    "        if category == \"automobile\":\n",
    "            print(f\"\\nDEBUG - Automobile search found {len(findings)} candidates\")\n",
    "            if not findings:\n",
    "                print(\"  No automobile amounts found - check if OCR is reading the text correctly\")\n",
    "        \n",
    "        # Group similar values (within 10%)\n",
    "        value_groups = []\n",
    "        for value, confidence in findings:\n",
    "            found_group = False\n",
    "            for group in value_groups:\n",
    "                if group:  # Check group is not empty\n",
    "                    group_median = np.median([v for v, c in group])\n",
    "                    if abs(value - group_median) / max(group_median, 1) < 0.1:  # Within 10%\n",
    "                        group.append((value, confidence))\n",
    "                        found_group = True\n",
    "                        break\n",
    "            if not found_group:\n",
    "                value_groups.append([(value, confidence)])\n",
    "        \n",
    "        # Select group with highest total confidence\n",
    "        if not value_groups:\n",
    "            return None\n",
    "            \n",
    "        best_group = max(value_groups, key=lambda g: sum(c for v, c in g))\n",
    "        \n",
    "        # Return the value with highest confidence in best group\n",
    "        selected_value = max(best_group, key=lambda x: x[1])[0]\n",
    "        \n",
    "        if category == \"depreciation\":\n",
    "            print(f\"  Selected depreciation value: ${selected_value:,.0f}\")\n",
    "        \n",
    "        return selected_value\n",
    "\n",
    "    def correct_ocr_number_errors(self, value: float, category: str) -> float:\n",
    "        \"\"\"Correct common OCR errors in number recognition\"\"\"\n",
    "        if category == \"automobile\":\n",
    "            # Common OCR misreads for automobile expenses\n",
    "            ocr_corrections = {\n",
    "                1125: 15000,   # 1,125 -> 15,000\n",
    "                1120: 15000,   # 1,120 -> 15,000\n",
    "                11250: 15000,  # 11,250 -> 15,000\n",
    "                1500: 15000,   # 1,500 -> 15,000 (missing 0)\n",
    "                1250: 12500,   # Could be 12,500\n",
    "                1750: 17500,   # Could be 17,500\n",
    "            }\n",
    "            \n",
    "            # Direct correction\n",
    "            if value in ocr_corrections:\n",
    "                corrected = ocr_corrections[value]\n",
    "                print(f\"  Correcting OCR error: ${value:,.0f} -> ${corrected:,.0f}\")\n",
    "                return corrected\n",
    "            \n",
    "            # Pattern-based corrections\n",
    "            # If it's 1,1XX it might be 15,XXX\n",
    "            if 1100 <= value <= 1199:\n",
    "                # Extract last 2 digits\n",
    "                last_digits = int(str(int(value))[-2:])\n",
    "                potential_value = 15000 + last_digits\n",
    "                print(f\"  Possible OCR error: ${value:,.0f} might be ${potential_value:,.0f}\")\n",
    "                return potential_value\n",
    "                \n",
    "        return value\n",
    "\n",
    "    def validate_number_extraction(self, text, expected_pattern=\"automobile\"):\n",
    "        \"\"\"Specifically validate numbers near certain text\"\"\"\n",
    "        # Common OCR errors for numbers\n",
    "        ocr_corrections = {\n",
    "            '1120': '15000',  # 11,20 -> 15,000\n",
    "            '11200': '15000', # 112,00 -> 15,000\n",
    "            '1500': '15000',  # Missing last 0\n",
    "            '15': '15000',    # Missing 000\n",
    "            'IS000': '15000', # I instead of 1\n",
    "            'l5000': '15000', # l instead of 1\n",
    "        }\n",
    "        \n",
    "        # Find all numbers near the pattern\n",
    "        pattern = rf'{expected_pattern}[^0-9]*?([0-9,.$]+)'\n",
    "        matches = re.finditer(pattern, text, re.IGNORECASE)\n",
    "        \n",
    "        corrected_values = []\n",
    "        for match in matches:\n",
    "            raw_value = match.group(1).replace('$', '').replace(',', '').replace('.', '')\n",
    "            \n",
    "            # Check if this matches a known OCR error\n",
    "            if raw_value in ocr_corrections:\n",
    "                corrected_values.append(float(ocr_corrections[raw_value]))\n",
    "            else:\n",
    "                try:\n",
    "                    value = float(raw_value)\n",
    "                    # Sanity check for automobile expenses\n",
    "                    if expected_pattern == \"automobile\" and 1000 <= value <= 50000:\n",
    "                        corrected_values.append(value)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        return corrected_values\n",
    "    \n",
    "    def validate_amounts(self, extracted_values: Dict[str, float]) -> Dict[str, float]:\n",
    "        \"\"\"Validate extracted amounts for reasonableness\"\"\"\n",
    "        validated = {}\n",
    "        \n",
    "        # Validation rules\n",
    "        validation_rules = {\n",
    "            \"depreciation\": (0, 50000),  # Reasonable range for small business\n",
    "            \"officer_compensation\": (50000, 500000),\n",
    "            \"automobile\": (0, 50000),\n",
    "            \"meals\": (0, 5000),\n",
    "            \"charitable\": (0, 50000),\n",
    "            \"section179\": (0, 1000000)  # Section 179 limit\n",
    "        }\n",
    "        \n",
    "        for item, value in extracted_values.items():\n",
    "            if item in validation_rules:\n",
    "                min_val, max_val = validation_rules[item]\n",
    "                if min_val <= value <= max_val:\n",
    "                    validated[item] = value\n",
    "                else:\n",
    "                    print(f\"Warning: {item} value ${value:,.0f} outside expected range\")\n",
    "        \n",
    "        return validated\n",
    "    \n",
    "    def analyze_automatically(self, pdf_path: str) -> Dict:\n",
    "        \"\"\"Fully automatic analysis without manual intervention\"\"\"\n",
    "        print(\"Starting automatic analysis...\")\n",
    "        \n",
    "        # Extract with multiple methods and confidence scoring\n",
    "        all_findings = self.extract_with_validation(pdf_path)\n",
    "        \n",
    "        # Select best value for each category\n",
    "        extracted_values = {}\n",
    "        for category, findings in all_findings.items():\n",
    "            best_value = self.select_best_value(findings, category)\n",
    "            \n",
    "            # Apply OCR correction for automobile\n",
    "            if best_value and category == \"automobile\":\n",
    "                corrected_value = self.correct_ocr_number_errors(best_value, category)\n",
    "                if corrected_value != best_value:\n",
    "                    print(f\"Applied OCR correction for {category}: ${best_value:,.0f} -> ${corrected_value:,.0f}\")\n",
    "                    best_value = corrected_value\n",
    "            \n",
    "            if best_value:\n",
    "                extracted_values[category] = best_value\n",
    "                print(f\"Found {category}: ${best_value:,.0f} (from {len(findings)} candidates)\")\n",
    "            else:\n",
    "                print(f\"Could not find {category}\")\n",
    "                # Special handling for automobile - might be in \"Other Deductions\"\n",
    "                if category == \"automobile\":\n",
    "                    print(\"  Tip: Check 'Other Deductions' section of Schedule K\")\n",
    "        \n",
    "        # Validate amounts\n",
    "        validated_values = self.validate_amounts(extracted_values)\n",
    "        \n",
    "        # Calculate addbacks\n",
    "        addbacks = []\n",
    "        for item_type, amount in validated_values.items():\n",
    "            if item_type in self.addback_rules:\n",
    "                rule = self.addback_rules[item_type]\n",
    "                \n",
    "                if rule[\"calc_type\"] == \"excess_over_market\":\n",
    "                    if amount > self.market_rate_salary:\n",
    "                        excess = amount - self.market_rate_salary\n",
    "                        addbacks.append(Addback(\n",
    "                            line_item=f\"Officer Compensation (Excess over market)\",\n",
    "                            amount=excess,\n",
    "                            reason=rule[\"reason\"],\n",
    "                            calculation=f\"${amount:,.0f} - ${self.market_rate_salary:,.0f} = ${excess:,.0f}\",\n",
    "                            confidence=0.9\n",
    "                        ))\n",
    "                \n",
    "                elif rule[\"calc_type\"] == \"percentage\":\n",
    "                    adjusted_amount = amount * rule[\"percentage\"]\n",
    "                    addbacks.append(Addback(\n",
    "                        line_item=f\"{item_type.replace('_', ' ').title()} ({int(rule['percentage']*100)}% personal use)\",\n",
    "                        amount=adjusted_amount,\n",
    "                        reason=rule[\"reason\"],\n",
    "                        calculation=f\"{int(rule['percentage']*100)}% × ${amount:,.0f} = ${adjusted_amount:,.0f}\",\n",
    "                        confidence=0.9\n",
    "                    ))\n",
    "                \n",
    "                else:  # full_amount\n",
    "                    addbacks.append(Addback(\n",
    "                        line_item=item_type.replace('_', ' ').title(),\n",
    "                        amount=amount,\n",
    "                        reason=rule[\"reason\"],\n",
    "                        calculation=f\"Full amount: ${amount:,.0f}\",\n",
    "                        confidence=0.9\n",
    "                    ))\n",
    "        \n",
    "        # Items not found that might need investigation\n",
    "        expected_items = set(self.addback_rules.keys())\n",
    "        found_items = set(validated_values.keys())\n",
    "        missing_items = expected_items - found_items\n",
    "        \n",
    "        if missing_items:\n",
    "            print(f\"\\nWarning: Could not extract: {', '.join(missing_items)}\")\n",
    "        \n",
    "        return {\n",
    "            \"extracted_values\": validated_values,\n",
    "            \"addbacks\": addbacks,\n",
    "            \"total_addbacks\": sum(ab.amount for ab in addbacks),\n",
    "            \"missing_items\": list(missing_items),\n",
    "            \"extraction_confidence\": len(validated_values) / len(expected_items)\n",
    "        }\n",
    "    \n",
    "    def generate_report(self, results: Dict) -> str:\n",
    "        \"\"\"Generate comprehensive report\"\"\"\n",
    "        report = \"\\nAUTOMATIC EBITDA ADDBACK ANALYSIS\\n\"\n",
    "        report += \"=\" * 60 + \"\\n\"\n",
    "        \n",
    "        # Extraction confidence\n",
    "        confidence = results.get(\"extraction_confidence\", 0)\n",
    "        report += f\"\\nExtraction Confidence: {confidence:.0%}\\n\"\n",
    "        \n",
    "        if confidence < 0.7:\n",
    "            report += \"⚠️  Low extraction confidence - manual review recommended\\n\"\n",
    "        \n",
    "        # Addbacks\n",
    "        report += \"\\nIDENTIFIED ADDBACKS:\\n\"\n",
    "        report += \"-\" * 60 + \"\\n\"\n",
    "        \n",
    "        for addback in results[\"addbacks\"]:\n",
    "            report += f\"\\n{addback.line_item}\"\n",
    "            if addback.confidence < 0.8:\n",
    "                report += \" ⚠️\"\n",
    "            report += f\"\\n  Amount: ${addback.amount:,.2f}\"\n",
    "            report += f\"\\n  Reason: {addback.reason}\"\n",
    "            report += f\"\\n  Calculation: {addback.calculation}\\n\"\n",
    "        \n",
    "        # Total\n",
    "        report += \"-\" * 60 + \"\\n\"\n",
    "        report += f\"TOTAL ADDBACKS: ${results['total_addbacks']:,.2f}\\n\"\n",
    "        \n",
    "        # Missing items\n",
    "        if results.get(\"missing_items\"):\n",
    "            report += f\"\\n⚠️  Could not extract: {', '.join(results['missing_items'])}\\n\"\n",
    "            report += \"These items may need manual review.\\n\"\n",
    "        \n",
    "        return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5e0d499b-ba2b-4545-86d7-17413cc2d493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting automatic analysis...\n",
      "Processing page 1...\n",
      "Processing page 2...\n",
      "Processing page 3...\n",
      "Processing page 4...\n",
      "Processing page 5...\n",
      "\n",
      "DEBUG - All depreciation values found:\n",
      "  $1,373 (confidence: 0.6)\n",
      "  $1,373 (confidence: 0.6)\n",
      "  $1,373 (confidence: 0.6)\n",
      "  $1,373 (confidence: 0.6)\n",
      "  $1,373 (confidence: 0.6)\n",
      "  $1,373 (confidence: 0.6)\n",
      "  $1,373 (confidence: 0.6)\n",
      "  $1,373 (confidence: 0.6)\n",
      "  $1,373 (confidence: 0.6)\n",
      "  $1,373 (confidence: 0.6)\n",
      "  $1,373 (confidence: 0.6)\n",
      "  $1,373 (confidence: 0.6)\n",
      "  $1,998 (confidence: 0.9)\n",
      "  $4,562 (confidence: 0.6)\n",
      "  $4,562 (confidence: 0.6)\n",
      "  $4,562 (confidence: 0.6)\n",
      "  $4,562 (confidence: 0.6)\n",
      "  $4,562 (confidence: 0.6)\n",
      "  $4,562 (confidence: 0.6)\n",
      "  $4,562 (confidence: 0.6)\n",
      "  $4,562 (confidence: 0.6)\n",
      "  $4,562 (confidence: 0.6)\n",
      "  $4,562 (confidence: 0.6)\n",
      "  $4,562 (confidence: 0.6)\n",
      "  $4,562 (confidence: 0.6)\n",
      "  $4,797 (confidence: 0.9)\n",
      "  $4,797 (confidence: 0.9)\n",
      "  $4,797 (confidence: 0.9)\n",
      "  $4,797 (confidence: 0.9)\n",
      "  $4,797 (confidence: 0.9)\n",
      "  $4,797 (confidence: 0.9)\n",
      "  $4,797 (confidence: 0.9)\n",
      "  $4,797 (confidence: 0.9)\n",
      "  $4,797 (confidence: 0.9)\n",
      "  $4,797 (confidence: 0.9)\n",
      "  $4,797 (confidence: 0.9)\n",
      "  $4,797 (confidence: 0.9)\n",
      "  After filtering < $3,000: 13 values remain\n",
      "  Values in MACRS range ($1,000-$2,000): 13\n",
      "  Selected depreciation value: $1,373\n",
      "Found depreciation: $1,373 (from 37 candidates)\n",
      "Found officer_compensation: $200,115 (from 66 candidates)\n",
      "\n",
      "DEBUG - Automobile search found 1249 candidates\n",
      "  Correcting OCR error: $1,125 -> $15,000\n",
      "Applied OCR correction for automobile: $1,125 -> $15,000\n",
      "Found automobile: $15,000 (from 1249 candidates)\n",
      "Found meals: $183 (from 28 candidates)\n",
      "Found charitable: $3,975 (from 9 candidates)\n",
      "Found section179: $12,721 (from 54 candidates)\n",
      "\n",
      "AUTOMATIC EBITDA ADDBACK ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Extraction Confidence: 100%\n",
      "\n",
      "IDENTIFIED ADDBACKS:\n",
      "------------------------------------------------------------\n",
      "\n",
      "Depreciation\n",
      "  Amount: $1,373.00\n",
      "  Reason: Non-cash expense. Added back for EBITDA calculation as it doesn't affect cash flow.\n",
      "  Calculation: Full amount: $1,373\n",
      "\n",
      "Officer Compensation (Excess over market)\n",
      "  Amount: $4,415.00\n",
      "  Reason: Owner salary exceeds market rate. Excess amount is added back to normalize earnings.\n",
      "  Calculation: $200,115 - $195,700 = $4,415\n",
      "\n",
      "Automobile (25% personal use)\n",
      "  Amount: $3,750.00\n",
      "  Reason: 25% assumed personal use. This portion is discretionary/non-business expense.\n",
      "  Calculation: 25% × $15,000 = $3,750\n",
      "\n",
      "Meals\n",
      "  Amount: $183.00\n",
      "  Reason: Non-deductible portion (50%) represents discretionary spending.\n",
      "  Calculation: Full amount: $183\n",
      "\n",
      "Charitable\n",
      "  Amount: $3,975.00\n",
      "  Reason: Non-business expense. Charitable giving is discretionary.\n",
      "  Calculation: Full amount: $3,975\n",
      "\n",
      "Section179\n",
      "  Amount: $12,721.00\n",
      "  Reason: Accelerated depreciation election. Added back as it's a non-cash tax benefit.\n",
      "  Calculation: Full amount: $12,721\n",
      "------------------------------------------------------------\n",
      "TOTAL ADDBACKS: $26,417.00\n",
      "\n",
      "\n",
      "Results exported to automatic_addback_analysis.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Main Execution\n",
    "analyzer = ProductionAddbackAnalyzer()\n",
    "\n",
    "# Simply provide the PDF path - no manual values needed!\n",
    "pdf_path = \"Roselle_Dental_Center_2022_Modified.pdf\"  # <-- CHANGE THIS\n",
    "\n",
    "# Fully automatic analysis\n",
    "results = analyzer.analyze_automatically(pdf_path)\n",
    "\n",
    "# Generate report\n",
    "report = analyzer.generate_report(results)\n",
    "print(report)\n",
    "\n",
    "# Export to Excel\n",
    "if results[\"addbacks\"]:\n",
    "    df = pd.DataFrame([{\n",
    "        \"Item\": ab.line_item,\n",
    "        \"Amount\": ab.amount,\n",
    "        \"Reason\": ab.reason,\n",
    "        \"Calculation\": ab.calculation,\n",
    "        \"Confidence\": f\"{ab.confidence:.0%}\"\n",
    "    } for ab in results[\"addbacks\"]])\n",
    "    \n",
    "    df.to_excel(\"automatic_addback_analysis.xlsx\", index=False)\n",
    "    print(\"\\nResults exported to automatic_addback_analysis.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03225fbe-df72-4bd4-b299-1d87e5b7562b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d46686c-d814-4d87-88c5-d3b284848817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf0a26-e601-4879-8b25-5c72f0daef3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
